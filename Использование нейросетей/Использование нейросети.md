Очень многие нейросети можно искать на портале 
```
https://huggingface.co/ai-forever/ru-clip/tree/main
```

ai-forever - Это команда сбера, обучает и выкладывает разные модели

Например как использовать модель по текстовому и картиночной обработке ruclip-vit-base-patch32-384
Данную модель я смог запустить только при клонировании репозитория
```
https://github.com/ai-forever/ru-clip.git
```

Дальше устанавливаем зависимости
Основная 
```
ruclip==0.0.2
```
В добавок к ней идут многие другие [[Зависимости для нейросети ruclip-vit-base-patch32-384]]

Дальше создаем файл для теста и запуска
Н-р:
```python
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
import numpy as np
import seaborn as sns
import ruclip
import torch
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity

device = 'cpu'
# clip, processor = ruclip.load('ruclip-vit-large-patch14-336', device=device)
clip, processor = ruclip.load('ruclip-vit-base-patch32-384', device=device)

bs4_urls = [
    "./pics/yellow.png",
    "./pics/blue.png",
    "./pics/corner_sofa.png",
    "./pics/grey.png",
    "./pics/table.png",
    "./pics/closet.png",
    "./pics/flower.png",
]
classes = ["Желтый диван", "Синий диван", "Угловой диван", "Серый диван", "Стол", "Шкаф", "Диван с цветочками"]
images = [Image.open(bs4_url) for bs4_url in bs4_urls]

# classes = ['Диван', 'Подушка в цветочек', 'Подушка', 'Стол', 'Шкаф', ]
templates = ['{}', 'это {}', 'на картинке {}', 'это {}, домашнее животное']

predictor = ruclip.Predictor(clip, processor, device, bs=8, templates=templates)
with torch.no_grad():
    text_latents = predictor.get_text_latents(classes)
    image_latents = predictor.get_image_latents(images)

similarity_matrix = cosine_similarity(text_latents.cpu().numpy(), image_latents.cpu().numpy())

plt.figure(figsize=(12, 8))

ax = sns.heatmap(similarity_matrix, annot=True, fmt=".2f", cmap='viridis', cbar=False)
ax.set_yticklabels(classes, rotation=0)
ax.set_xticklabels(['' for _ in range(len(bs4_urls))])

num_classes = len(classes)
num_images = len(images)

for idx, image in enumerate(images):
    image.thumbnail((50, 50))  # Миниатюра изображения
    imagebox = OffsetImage(np.array(image), zoom=1)
    
    # Динамическое позиционирование
    x_position = idx + 0.5  # Ось X — просто расположение между границами клеток
    y_position = 0.01  # Ось Y
    
    # Добавляем миниатюру на тепловую карту
    ab = AnnotationBbox(imagebox, (x_position, y_position), frameon=False, box_alignment=(0.5, -0.25))
    ax.add_artist(ab)


plt.subplots_adjust(left=0.2, right=0.9, top=0.8, bottom=0.1)
plt.savefig("heatmap1.png", bbox_inches='tight', pad_inches=2.0)
```

Тут происходит определение процессора, преобразование картинки и текста в вектор, сравнение по принципу косинусов, и выведение тепловой карты.
Результат сравнения такой

![[heatmap1.png]]