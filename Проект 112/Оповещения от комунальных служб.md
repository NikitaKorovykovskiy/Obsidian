def start_broadcast(broadcast_id: int, senders, create_voice=True, logger=None):

Как запустить локально можно использовать команду git stash list, я сохранил туда изменения для настройки
#### Настройки конфигурации
#### Измени nginx.conf
```nginx
user root;
worker_processes 6;
worker_rlimit_nofile 65535;
  
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;
  
events {
worker_connections 4096;
}

http {
server_tokens off;
sendfile on;
aio on;
tcp_nopush on;
keepalive_timeout 60;
tcp_nodelay on;

include /etc/nginx/mime.types;
default_type application/octet-stream;

log_format main '$remote_addr - $remote_user [$time_local] "$request" '
'$status $body_bytes_sent "$http_referer" '
'"$http_user_agent" "$http_x_forwarded_for"';

access_log /var/log/nginx/access.log main;

upstream backend {
server backend:8000;
}

# upstream esia-service {
# server esia-service:8080;
# }

# upstream geo-service {
# server geo-service:8080;
# }

upstream geo-service-python {
server geo-service-python:8000;
}

upstream sms-service {
server sms_channel:8000;
}

# this is required to proxy Grafana Live WebSocket connections.
map $http_upgrade $connection_upgrade {
default upgrade;
'' close;
}

server {
listen 80 default deferred;
server_name _ ;

proxy_buffer_size 32k;
proxy_buffers 4 32k;
proxy_busy_buffers_size 32k;

gzip on;
gzip_disable "msie6";
gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript;

gzip_comp_level 5;

client_max_body_size 20m;
keepalive_timeout 10 3;
proxy_connect_timeout 300;
proxy_send_timeout 300;
proxy_read_timeout 300;
send_timeout 300;

root /var/www/;

# Nginx and Angularjs with html mode 5 - https://gist.github.com/cjus/b46a243ba610661a7efb
index index.html;

  
# location ~ ^/api/geo/* {

# rewrite ^/api/geo/(.*) /api/yenisei-gis/$1 break;

# proxy_pass http://geo-service;

# proxy_set_header Host $http_host; # required for docker client's sake

# proxy_set_header X-Real-IP $remote_addr; # pass on real client's IP

# proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

# #proxy_set_header X-Forwarded-Proto https;

# # CORS conf

# # todo: enable this block only for allowed hosts

# # add_header 'Access-Control-Allow-Origin' "*" always;

# # add_header 'Access-Control-Allow-Credentials' 'true' always;

# # add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;

# # add_header 'Access-Control-Allow-Headers' 'Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Requested-With' always;

# # # required to be able to read Authorization header in frontend

# # add_header 'Access-Control-Expose-Headers' 'Authorization' always;

# }

  

location ~ ^/api/pygeo/* {

rewrite ^/api/pygeo/(.*) /$1 break;

proxy_pass http://geo-service-python;

proxy_set_header Host $http_host; # required for docker client's sake

proxy_set_header X-Real-IP $remote_addr; # pass on real client's IP

proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

#proxy_set_header X-Forwarded-Proto https;

}

  

location ~ ^/api/sms/* {

rewrite ^/(.*)$ /$1 break;

proxy_pass http://sms-service;

proxy_set_header Host $http_host; # required for docker client's sake

proxy_set_header X-Real-IP $remote_addr; # pass on real client's IP

proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

#proxy_set_header X-Forwarded-Proto https;

}

  
  
  

# location ~ ^/api/esia/(login-start|login-finish|logout|login) {

# rewrite ^/api/esia/(.*) /api/$1 break;

# proxy_pass http://esia-service;

# proxy_set_header Host $http_host; # required for docker client's sake

# proxy_set_header X-Real-IP $remote_addr; # pass on real client's IP

# proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

# #proxy_set_header X-Forwarded-Proto https;

# }

  

location ~ ^/(admin|superadmin|reports|grappelli|docs|api|metrics) {

# proxy conf

proxy_pass http://backend;

proxy_set_header Host $http_host; # required for docker client's sake

proxy_set_header X-Real-IP $remote_addr; # pass on real client's IP

proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

#proxy_set_header X-Forwarded-Proto https;

# cors clear header before passing proxy

proxy_set_header 'Origin' '';

  

# CORS conf

# todo: enable this block only for allowed hosts

add_header 'Access-Control-Allow-Origin' "*" always;

add_header 'Access-Control-Allow-Credentials' 'true' always;

add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;

add_header 'Access-Control-Allow-Headers' 'Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Requested-With' always;

# required to be able to read Authorization header in frontend

add_header 'Access-Control-Expose-Headers' 'Authorization' always;

  

}

  
  
  
  

location ~ /static {

root /var/www;

}

  

location ~ /media {

root /var/www;

}

  

location ~ / {

try_files $uri $uri/ /index.html;

}

}

}
```

Затем измени docker-file
```docker
version: '3.4'

  

x-server-tmpl: &server-tmpl

env_file:

- .env

  

services:

  

backend:

build:

context: ./

dockerfile: Dockerfile.local

command: python manage.py runserver 0.0.0.0:8000

volumes:

- ./iss112/:/server/iss112/

- ./modules/:/server/modules/

- ./templates/:/server/templates/

# - ./media/:/server/media/

- ./log/:/server/log/

- ./backend/staticfiles/:/server/backend/staticfiles/

- ./backend/media/:/server/media/

ports:

- "8000:8000"

stdin_open: true # for ipdb

tty: true # for ipdb

depends_on:

- db

- celery

- redis

<<: *server-tmpl

db:

image: mdillon/postgis:10

ports:

- 5432:5432

volumes:

- ./postgres/data:/var/lib/postgresql/data

environment:

POSTGRES_DB: backend

POSTGRES_USER: postgres

POSTGRES_PASSWORD: postgres

redis:

image: redis:5.0.5

ports:

- 6379:6379

  

celery:

build:

context: ./

dockerfile: Dockerfile.local

command: celery -A modules.gateway worker -l DEBUG -c 4 -n celery_worker

volumes:

- ./iss112:/server/iss112

- ./modules:/server/modules

- ./log:/server/log

- ./media/:/server/media/

depends_on:

- db

- redis

<<: *server-tmpl

  

celery-scheduler:

build:

context: ./

dockerfile: Dockerfile.local

command: celery -A modules.gateway beat -l DEBUG

volumes:

- ./iss112:/server/iss112

- ./modules:/server/modules

- ./log:/server/log

depends_on:

- db

- redis

<<: *server-tmpl

#

# celery-sms:

# build:

# context: ./

# dockerfile: Dockerfile.local

# command: celery -A modules.gateway worker -l INFO -c 1 -Q sms-channel -n sms_worker

# volumes:

# - ./iss112:/server/iss112

# - ./modules:/server/modules

# - ./log:/server/log

# depends_on:

# - db

# - redis

# - rabbitmq

# <<: *server-tmpl

#

# celery-push:

# build:

# context: ./

# dockerfile: Dockerfile.local

# command: celery -A modules.gateway worker -l INFO -c 1 -Q push-channel -n push_worker

# volumes:

# - ./iss112:/server/iss112

# - ./modules:/server/modules

# - ./log:/server/log

# depends_on:

# - db

# - redis

# - rabbitmq

# <<: *server-tmpl

#

# celery-email:

# build:

# context: ./

# dockerfile: Dockerfile.local

# command: celery -A modules.gateway worker -l INFO -c 1 -Q email-channel -n email_worker

# volumes:

# - ./iss112:/server/iss112

# - ./modules:/server/modules

# - ./log:/server/log

# depends_on:

# - db

# - redis

# - rabbitmq

# <<: *server-tmpl

#

# celery-emergency:

# build:

# context: ./

# dockerfile: Dockerfile.local

# command: celery -A modules.gateway worker -l INFO -c 1 -Q emergency-channel -n emergency_worker

# volumes:

# - ./iss112:/server/iss112

# - ./modules:/server/modules

# - ./log:/server/log

# - ./media/:/server/media/

# depends_on:

# - db

# - redis

# - rabbitmq

# <<: *server-tmpl

#

# celery-tourist:

# build:

# context: ./

# dockerfile: Dockerfile.local

# command: celery -A modules.gateway worker -l INFO -c 1 -Q tourist-channel -n tourist_worker

# volumes:

# - ./iss112:/server/iss112

# - ./modules:/server/modules

# - ./log:/server/log

# depends_on:

# - db

# - redis

# - rabbitmq

# <<: *server-tmpl

  

flower:

build:

context: ./

dockerfile: Dockerfile.local

volumes:

- ./iss112:/server/iss112

- ./modules:/server/modules

- ./log:/server/log

command: celery flower -A modules.gateway --address=0.0.0.0 --port=5555

depends_on:

- backend

ports:

- 5555:5555

<<: *server-tmpl

  

channel_sms:

hostname: sms_channel

image: harbor.cifra-k.ru/notify-system/sender-channel-sms_htpp_master:latest

# image: harbor.cifra-k.ru/notify-system/sender-channel-sms_smpp_master:latest

ports:

- 9010:8000

volumes:

- ./backend/log/stat/sms:/opt/log

env_file:

- .env

restart: always

  

channel_push:

hostname: push_channel # TODO sms_channel

image: harbor.cifra-k.ru/notify-system/sender-channel-push_master:latest

#image: harbor.cifra-k.ru/notify-system/sender-channel-push_dev:latest

ports:

- 9011:8000

volumes:

- ./backend/log/stat/push:/opt/log

- ./backend/service-account-key.json:/opt/service-account-key.json

# - ./backend/service-account-key.json:/opt/service-account-key.json

# - ./backend/service-account-key.json:/opt/service-account-key.json

env_file:

- .env

environment:

- PYTHONUNBUFFERED=1

restart: always

  

channel_email:

hostname: email_channel

image: harbor.cifra-k.ru/notify-system/sender-channel-email_master:latest

ports:

- 9012:8000

volumes:

- ./backend/log/stat/email:/opt/log

env_file:

- .env

restart: always

flashcall-obit:

image: harbor.cifra-k.ru/common/flashcall-obit_master:latest

command: uvicorn main:app --port=8000 --host=0.0.0.0

volumes:

- ./backend/log/flashcall:/opt/logs

ports:

- "8045:8000"

env_file:

- .env

geo-service-python:

image: harbor.cifra-k.ru/common/geo-service-python_master:latest

command: uvicorn main:app --port=8000 --host=0.0.0.0

ports:

- "8050:8000"

environment:

YENISEI_KEY: dcnfjreidyf5tnmnodkx7dqp

gar-service-python:

image: harbor.cifra-k.ru/addresses-gar/addresses-gar-backend_master:latest

command: uvicorn main:app --port=8000 --host=0.0.0.0

ports:

- "8055:8000"

volumes:

- ./backend/logs/gar:/opt/logs

env_file:

- .env

  

grafana:

image: grafana/grafana:latest

ports:

- "3000:3000"

volumes:

- grafana_data:/var/lib/grafana

- ./grafana.ini:/etc/grafana/grafana.ini

depends_on:

- backend

  

prometheus:

image: prom/prometheus:latest

ports:

- "9090:9090"

depends_on:

- backend

command:

- "--config.file=/etc/prometheus/prometheus.yml"

- "--web.enable-lifecycle"

volumes:

- ./grafana/dashboards.yml:/var/lib/grafana/dashboards

- ./grafana/datasources.yml:/var/lib/grafana/datasources

- ./prometheus.yml:/etc/prometheus/prometheus.yml

- prometheus_data:/prometheus

frontend:

hostname: frontend

image: harbor.cifra-k.ru/notify-system/subscriptions-web_dev:latest

ports:

- 80:80

- 443:443

volumes:

- ./nginx/log:/var/log/nginx:rw

- ./nginx/nginx.conf:/etc/nginx/nginx.conf

- ./backend/staticfiles:/var/www/static

- ./backend/media:/var/www/media

depends_on:

- backend

restart: always

volumes:

grafana_data:

prometheus_data:

# celery-push_officials_notification:

# build:

# context: ./

# dockerfile: Dockerfile.local

# command: celery worker -A modules.officialsnotification -l INFO -c 1 -Q push-channel -n push_worker

# volumes:

# - ./iss112:/server/iss112

# - ./modules:/server/modules

# - ./log:/server/log

# depends_on:

# - db

# - redis

# - rabbitmq

# <<: *server-tmpl
```
Теперь перезапусти докер и зайди через порт 80 на создание сообщений



#### Более простая настройка
В файле modules/institutions_info/static/js/utils.js заменть
rootUrl: window.location.protocol + '//localhost:8050/',

### Принцип работы

Получаем:
1. `broadcast = Broadcast.objects.get(pk=broadcast_id)` (Информационное сообщение)
2. `priority_types = broadcast.priority.send_types` - Статус отправки
3. Те кому должны приходить ИС и ИСКС (Подписка на рассылку). Активные подписки
```python 
active_subscriptions = BroadcastSubscription.objects.filter(enabled=True)
``` 

4. Проверка на наличие у `broadcast` коммунального сообщения 
```python
if broadcast.communal:
	broadcast_communal_address = broadcast.communal.incident_address #Получение адреса указанного в ИСКС
	...
	query = Q() # Фильтрация по адресу указанном в МП пользователя
		for i in formatted_addresses:
		query |= Q(user__addresses__icontains=i)
  
	active_subscriptions = active_subscriptions.filter(query)
```